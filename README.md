# FarmIA â€“ Kafka y Procesamiento en Tiempo Real

Este proyecto tiene como objetivo construir un pipeline de procesamiento en tiempo real para FarmIA utilizando Apache Kafka y su ecosistema. El sistema permite integrar datos de sensores agrÃ­colas (IoT) y transacciones de ventas en lÃ­nea, generando informaciÃ³n valiosa para la toma de decisiones.

## Requisitos

Debes tener **Terraform instalado** en tu sistema para desplegar la infraestructura.  
Puedes descargarlo desde: [https://www.terraform.io/downloads.html](https://www.terraform.io/downloads.html)

### Versiones de Providers

Este proyecto utiliza las siguientes versiones de providers:

````hcl
terraform {
  required_providers {
    azurerm = {
      source  = "hashicorp/azurerm"
      version = "=3.0.0"
    }
    confluent = {
      source  = "confluentinc/confluent"
      version = "=2.34.0"
    }
  }
}

## Objetivo de la Tarea

Construir una soluciÃ³n de streaming basada en Kafka que:

1. Procese datos de sensores en tiempo real para detectar condiciones anÃ³malas.
2. Procese datos de transacciones en tiempo real para generar resumenes agregados minuto a minuto.
3. Use Kafka Streams o KSQLDB para generar:
   - Alertas ante anomalÃ­as de sensores.
   - ResÃºmenes de ventas por categorÃ­a de producto cada minuto.

---

## Estructura del Repositorio

```plaintext
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md                    # Este archivo
â””â”€â”€ terraform/
    â”œâ”€â”€ logs/                    # Logs de ejecuciÃ³n de las queries KSQL
    â”‚   â”œâ”€â”€ ksql-sales_data.log
    â”‚   â”œâ”€â”€ ksql-sales_summary.log
    â”‚   â”œâ”€â”€ ksql-sensor_alerts.log
    â”‚   â””â”€â”€ ksql-sensor_data.log
    â”œâ”€â”€ main.tf                  # Archivo principal de Terraform
    â”œâ”€â”€ terraform.tfvars.example# Plantilla de configuraciÃ³n
    â”œâ”€â”€ variables.tf            # DefiniciÃ³n de variables globales
    â”œâ”€â”€ modules/
    â”‚   â”œâ”€â”€ assets/
    â”‚   â”‚   â”œâ”€â”€ avro_schemas/   # Schemas AVRO (sensor y transacciones)
    â”‚   â”‚   â”œâ”€â”€ ksql/           # Queries KSQL en formato JSON
    â”‚   â”‚   â””â”€â”€ scripts/        # Scripts auxiliares como startup.sh
    â”‚   â”œâ”€â”€ azure_core/         # Infraestructura en Azure para la base de datos MySQL
    â”‚   â”œâ”€â”€ confluent_cluster/  # ConfiguraciÃ³n del clÃºster Kafka
    â”‚   â”œâ”€â”€ confluent_env/      # Entorno de variables Confluent
    â”‚   â”œâ”€â”€ connectors/         # DefiniciÃ³n de conectores Kafka Connect
    â”‚   â”œâ”€â”€ kafka_topics/       # DeclaraciÃ³n de los topics Kafka
    â”‚   â”œâ”€â”€ ksqldb/             # ConfiguraciÃ³n de KSQLDB
    â”‚   â”œâ”€â”€ schema_registry/    # Registro de schemas
    â”‚   â””â”€â”€ schemas/            # GestiÃ³n de schemas vÃ­a Terraform
````

## Setup del Entorno

1. Copia y edita las variables necesarias:

   ```bash
   cp terraform.tfvars.example terraform.tfvars
   ```

2. Ajusta las variables en `terraform.tfvars` segÃºn tu entorno.

3. Aplica la infraestructura:
   ```bash
   cd terraform
   terraform apply -auto-approve
   ```

---

## Kafka Topics

Los siguientes topics son creados automÃ¡ticamente y usados durante el flujo de procesamiento:

- `_transacions`: simula la llegada de transacciones que son almacenadas en MySQL.
- `sensor-telemetry`: recibe datos generados por sensores IoT.
- `sales-transactions`: recibe datos de ventas extraÃ­dos de MySQL.
- `sensor-alerts`: recibe las alertas generadas por anomalÃ­as en sensores.
- `sales-summary`: contiene los resÃºmenes de ventas por categorÃ­a.

---

## Kafka Connect

Se utilizan conectores para integrar fuentes externas a Kafka:

- **MySQL Source Connector**: ðŸ”² _[por definir por el alumno]_  
  Conecta la base de datos relacional y publica en `sales-transactions`.

- **MySQL Sink Connector**: ðŸ”² _[por definir por el alumno]_  
  Conecta la base de datos relacional y publica en `sales-transactions`.

- **Datagen Connector**: ðŸ”² _[por definir por el alumno]_
  - Simula datos de sensores agrÃ­colas en el topic `sensor-telemetry`.
  - Simula datos de transacciones en el topic `_transacctions`.

La configuraciÃ³n de los conectores encuentran a partir de la lÃ­nea 140 en `terraform/main.tf`.

---

## Kafka Streams / KSQL

El procesamiento en tiempo real se realiza mediante Kafka Streams o KSQLDB. Se implementan dos flujos principales:

1. **DetecciÃ³n de AnomalÃ­as (Sensores)**

   - Input: `sensor-telemetry`
   - Condiciones: temperatura > 35â€¯Â°C o humedad < 20â€¯%
   - Output: `sensor-alerts`

2. **Resumen de Ventas por CategorÃ­a**
   - Input: `sales-transactions`
   - Agrega el total de ingresos por categorÃ­a de producto cada minuto
   - Output: `sales-summary`

Las queries se encuentran en `modules/assets/ksql/`.

---

## Shutdown del Entorno

Por motivos de seguridad y control explÃ­cito, el apagado de la infraestructura debe hacerse de forma manual. Esto evita eliminaciones accidentales de recursos crÃ­ticos en ambientes compartidos o en producciÃ³n.

Al ejecutar terraform destroy -auto-approve saltarÃ¡ un error de falta de permisos.
